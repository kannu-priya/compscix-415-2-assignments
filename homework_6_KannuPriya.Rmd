---
title: "Compscix-415-2-Homework 6"
author: "Kannu Priya Arora"
date: "Mar 10, 2018"
output: 
  html_document :
  toc : TRUE
---

```{r load_packages, include=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(mosaicData)
```


## Exercise 1
*Load the Whickham dataset (data(Whickham)).*

  1. *What variables are in this data set?*
  
  whickham dataset has 3 variables:
  
  * outcome - women survival status after 20 years of first survey
  
  * smoker - smoking status
  
  * age - at the time of first survey
  
  
  2. *How many observations are there and what does each represent?*
  
  There are 1314 observations in the dataset representing women and their survival status after 20 years of initial survey.
  
  3. *Create a table (use the R code below as a guide) and a visualization of the relationship between smoking status and outcome, ignoring age. What do you see? Does it make sense?*
  
  The table and graph below shows how many women are alive after 20 years and how being a smoker affected the probability of women being alive. Age has been ignored.
  as we can see in the graph, the ratio of women who used to smoke were more likely to be alive as compared to women who never smoked. The relationship of 2 factors - outcome and smoker does not make sense in itself and should be looked at along with age as confounding variable.
  
  
```{r}
Whickham %>% count(smoker, outcome) %>%
  ggplot(mapping = aes(x=outcome))+
  geom_bar(aes(fill = smoker), position = "fill")
```

  
4. *Recode the age variable into an ordered factor with three categories: age <= 44, age > 44 & age <= 64, and age > 64. Now, recreate visualization from above, but facet on your new age factor. What do you see? Does it make sense?*

The graph below uncovers the impact of confounding variable, the age. For all the 3 age groups - below 44 years, between 44 and 64 and above 64 years, the ratio of women who smoked and are dead in 20 years survey duration is higher as compared to similar proportion in alive group. This explains the Simpson's paradox affect we saw in previous question.


```{r}
Whickham2 <- Whickham %>% mutate(age_fct = factor(case_when(age<=44 ~ 'Below44',
                                                            age>44 & age<=64 ~ 'between',
                                                            age>64 ~ 'above64'),
                                                  levels = c('Below44', 'between', 'above64')))
Whickham2 %>% ggplot(mapping = aes(x=outcome))+
  geom_bar(aes(fill = smoker), position = "fill")+
  facet_wrap(~age_fct)
```

***

##  Exercise 2

*The Central Limit Theorem states that the sampling distribution of sample means is approximately Normal, regardless of the distribution of your population. For this exercise our population distribution will be a Gamma(1,2) distribution, and weâ€™ll show that the sampling distribution of the mean is in fact normally distributed.*

  1. *Generate a random sample of size n = 10000 from a gamma(1,2) distribution and plot a histogram or density curve. Use the code below to help you get your sample.*


```{r}
n <- 10000
# look at ?rgamma to read about this function
gamma_samp <- tibble(x = rgamma(n, shape = 1, scale = 2))

ggplot(gamma_samp, mapping = aes(x))+
  geom_density()

```


  2.  *What is the mean and standard deviation of your sample? They should both be close to 2 because for a gamma distribution:*
*mean = shape x scale*
*variance = shape x scale^2*

For the sample taken, mean is 2.029 and standard deviation is 2.037 

```{r}
(mean_samp <- gamma_samp %>% .[['x']] %>% mean())
sd(gamma_samp$x)

```

  3.  *Pretend the distribution of our population of data looks like the plot above. Now take a sample of size n = 30 from a Gamma(1,2) distribution, plot the histogram or density curve, and calculate the mean and standard deviation.*


```{r}
s30 <- gamma_samp %>% sample_n(30)

s30 %>% summarise(Sample_mean = mean(x), std_dev = sd(x))

s30 %>% ggplot(mapping = aes(x)) +
  geom_density() +
  geom_vline(aes(xintercept=mean(x)), 
            color="blue")

```

  4.  *Take a sample of size n = 30, again from the Gamma(1,2) distribution, calculate the mean, and assign it to a vector named mean_samp. Repeat this 10000 times!!!! The code below might help.*


```{r}
mean_samp <- rep(NA, 10000)

# start a loop
for(i in 1:10000) {
  g_samp <- rgamma(30, shape = 1, scale = 2)
  mean_samp[i] <- mean(g_samp)
}
# Convert vector to a tibble
mean_samp <- tibble(mean_samp)
```


  5. *Make a histogram of your collection of means from above (mean_samp).*
  
  
```{r}
ggplot(mean_samp, mapping= aes(mean_samp))+
  geom_histogram(binwidth = 0.01)
```


  6.  *Calculate the mean and standard deviation of all of your sample means.*
  
```{r}
mean_samp %>% summarise(mean2 = mean(mean_samp), std_dev = sd(mean_samp))
```

  
  7.  *Did anything surprise you about your answers to #6?*
  
  The mean value is very close to what we got in previous questions but the same is not true for standard deviation. The standard deviation has significantly reduced in the last vector of 1000 iterations. This makes sense as we have multiple iterations of data to absorb the deviations and thus show a normal distribution.   
  
  8.  *According to the Central Limit Theorem, the mean of your sampling distribution should be very close to 2, and the standard deviation of your sampling distribution should be close to 0.365. Repeat #4-#6, but now with a sample of size n = 300 instead. Do your results match up well with the theorem?*
  
  As per theorem, the mean of sampling distribution has to be close to 2. With new n = 300, the value of standard deviation should be 2/ square root 300 = 0.116. This is very close to what we have got below.
  
  
```{r}
mean_samp <- rep(NA, 10000)

for(i in 1:10000) {
  g_samp <- rgamma(300, shape = 1, scale = 2)
  mean_samp[i] <- mean(g_samp)
}
# Convert vector to a tibble
mean_samp <- tibble(mean_samp)

ggplot(mean_samp, mapping= aes(mean_samp))+
  geom_histogram(binwidth = 0.01)

mean_samp %>% summarise(mean2 = mean(mean_samp), std_dev = sd(mean_samp))
```
